# -*- coding: utf-8 -*-
"""251125_ë¶€ë™ì‚°agent_ì •ì±…ë°˜ì˜.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1a2C8FqV_L9VoiUWa7164jA0AOQpXj6s0
"""

!pip install -q \
  "langchain==0.2.16" \
  "langchain-community==0.2.12" \
  "langchain-core==0.2.38" \
  "langsmith<0.2.0" \
  "sentence-transformers" \
  "elasticsearch" \
  "duckduckgo-search" \
  "pypdf"

import langchain
from sentence_transformers import SentenceTransformer
from elasticsearch import Elasticsearch
from duckduckgo_search import DDGS
from pypdf import PdfReader

print("ëª¨ë“ˆ ì„í¬íŠ¸ ì„±ê³µ!")

# Commented out IPython magic to ensure Python compatibility.
# %pip uninstall -y jax jaxlib

# Commented out IPython magic to ensure Python compatibility.
# %pip install -q \
  "langchain==0.2.16" \
  "langchain-community==0.2.12" \
  "langchain-core==0.2.38" \
  "langsmith<0.2.0" \
  sentence-transformers \
  elasticsearch \
  duckduckgo-search \
  pypdf

# Commented out IPython magic to ensure Python compatibility.
# %pip uninstall -y sentence-transformers huggingface-hub

# Commented out IPython magic to ensure Python compatibility.
# %pip install -q \
  "sentence-transformers==2.2.2" \
  "huggingface_hub==0.16.4"

import langchain
from sentence_transformers import SentenceTransformer
from elasticsearch import Elasticsearch
from duckduckgo_search import DDGS
from pypdf import PdfReader

print("âœ… ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„í¬íŠ¸ ì„±ê³µ!")

# Commented out IPython magic to ensure Python compatibility.
# %pip install -q \
  "langchain==0.2.16" \
  "langchain-community==0.2.12" \
  "langchain-core==0.2.38" \
  "langsmith<0.2.0" \
  "huggingface_hub==0.14.1" \
  "sentence-transformers==2.2.2" \
  elasticsearch \
  duckduckgo-search \
  pypdf \
  torch

# Commented out IPython magic to ensure Python compatibility.
# %pip install -q \
  "langchain==0.2.16" \
  "langchain-community==0.2.12" \
  "langchain-core==0.2.38" \
  "langchain-openai==0.1.23" \
  elasticsearch \
  duckduckgo-search \
  pypdf

from langchain_openai import ChatOpenAI, OpenAIEmbeddings
from elasticsearch import Elasticsearch
from duckduckgo_search import DDGS
from pypdf import PdfReader

print("âœ… ì„í¬íŠ¸ ì„±ê³µ!")

# Commented out IPython magic to ensure Python compatibility.
# %pip install -q InstructorEmbedding

# === ê³µí†µ import ===
import os
from datetime import date, timedelta
from typing import List, Dict, Any, Tuple, Optional

from elasticsearch import Elasticsearch
from langchain_openai import ChatOpenAI, OpenAIEmbeddings
from duckduckgo_search import DDGS
from pypdf import PdfReader  # ë‚˜ì¤‘ì— ì •ì±… PDF ì¸ë±ì‹± ë•Œ ì‚¬ìš©

# === OpenAI API Key (Colabì—ì„œ ì•ˆì „í•˜ê²Œ ì…ë ¥) ===
import getpass

if "OPENAI_API_KEY" not in os.environ:
    os.environ["OPENAI_API_KEY"] = getpass.getpass("ğŸ”‘ OpenAI API Key ì…ë ¥: ")

# === ElasticSearch í™˜ê²½ì„¤ì • ===
ES_HOST = os.getenv("ES_HOST", "https://my-elasticsearch-project-b71e61.es.us-central1.gcp.elastic.cloud:443")          # ë„¤ ES ì£¼ì†Œ
ES_REAL_INDEX = os.getenv("ES_REAL_INDEX", "realestate_hybrid")  # ì‹¤ê±°ë˜/ë§¤ë¬¼ ì¸ë±ìŠ¤
ES_POLICY_INDEX = os.getenv("ES_POLICY_INDEX", "gov_policy_korea")  # ì •ì±… PDF ì¸ë±ìŠ¤

# === ES í´ë¼ì´ì–¸íŠ¸ ìƒì„± ===
es = Elasticsearch(ES_HOST)

def check_es():
    if not es.ping():
        raise RuntimeError(f"Elasticsearch({ES_HOST}) ê°€ ì‘ë‹µí•˜ì§€ ì•ŠìŠµë‹ˆë‹¤. Docker/Cloud ìƒíƒœë¥¼ í™•ì¸í•˜ì„¸ìš”.")

# === LLM & Embedding ì„¤ì • ===
llm = ChatOpenAI(model="gpt-4o-mini", temperature=0.2)

# text-embedding-3-small: 1536ì°¨ì›, ê°€ê²© ì €ë ´, í•œê¸€ë„ ê´œì°®ìŒ
embedding_model = OpenAIEmbeddings(model="text-embedding-3-small")

def embed_query(text: str) -> List[float]:
    """
    OpenAI ì„ë² ë”©ì„ ì‚¬ìš©í•´ ì¿¼ë¦¬ë¥¼ ë²¡í„°(list[float])ë¡œ ë³€í™˜.
    ES knn ì¿¼ë¦¬ì— ê·¸ëŒ€ë¡œ ë„£ì–´ ì“¸ ìˆ˜ ìˆë‹¤.
    """
    return embedding_model.embed_query(text)

import os, getpass
from elasticsearch import Elasticsearch

# 1) Elastic Cloud endpoint (ë³µë¶™)
ES_HOST = "https://my-elasticsearch-project-b71e61.es.us-central1.gcp.elastic.cloud:443"

# 2) API KeyëŠ” getpassë¡œ ì…ë ¥í•´ì„œ ë…¸íŠ¸ë¶ì— ì•ˆ ë‚¨ê²Œ
if "ES_API_KEY" not in os.environ:
    os.environ["ES_API_KEY"] = getpass.getpass("ğŸ”‘ Elastic API Key ì…ë ¥: ")

ES_API_KEY = os.environ["ES_API_KEY"]

# 3) ES í´ë¼ì´ì–¸íŠ¸ ìƒì„± (API key ì¸ì¦)
es = Elasticsearch(
    ES_HOST,
    api_key=ES_API_KEY,
    verify_certs=True,
    request_timeout=30,
)

def check_es():
    try:
        info = es.info()
        print("[ES ì—°ê²° ì„±ê³µ]", info["cluster_name"], info["version"]["number"])
        return True
    except Exception as e:
        raise RuntimeError(f"Elasticsearch({ES_HOST}) ì—°ê²° ì‹¤íŒ¨: {e}")

from langchain.text_splitter import RecursiveCharacterTextSplitter

# Colabì— ì—…ë¡œë“œí•œ ì •ì±… PDF ê²½ë¡œ
POLICY_PDFS = [
    "/content/R25_0627.pdf",
    "/content/R25_0907.pdf",
    "/content/R25_1015.pdf",
]

def parse_date_from_filename(filename: str) -> str:
    """
    íŒŒì¼ëª… ì˜ˆ: R25_0627.pdf â†’ 2025-06-27 ë¡œ ë³€í™˜ (ì—°ë„ëŠ” 2025ë¡œ ê°€ì •)
    """
    base = os.path.basename(filename)
    mmdd = base.split("_")[1].split(".")[0]  # "0627"
    mm = mmdd[:2]
    dd = mmdd[2:]
    return f"2025-{mm}-{dd}"


def create_policy_index_if_needed():
    """
    ì •ì±… ì¸ë±ìŠ¤ê°€ ì—†ìœ¼ë©´ text-embedding-3-small ì°¨ì›(1536)ìœ¼ë¡œ ìƒì„±.
    """
    check_es()
    if es.indices.exists(index=ES_POLICY_INDEX):
        print(f"[INFO] index '{ES_POLICY_INDEX}' already exists. skip create.")
        return

    dims = 1536  # text-embedding-3-small
    mapping = {
        "mappings": {
            "properties": {
                "content": {"type": "text"},
                "embedding": {
                    "type": "dense_vector",
                    "dims": dims,
                    "index": True,
                    "similarity": "cosine",
                },
                "policy_name": {"type": "keyword"},
                "published_date": {"type": "date", "format": "yyyy-MM-dd||strict_date_optional_time"},
                "source_file": {"type": "keyword"},
            }
        }
    }
    es.indices.create(index=ES_POLICY_INDEX, body=mapping)
    print(f"[INFO] created index '{ES_POLICY_INDEX}' (dims={dims})")


def index_policy_pdfs(pdf_paths: List[str]):
    """
    ìµœê·¼ 3ê°œ ì •ì±… PDFë¥¼:
      1) í˜ì´ì§€ ë‹¨ìœ„ë¡œ ë¡œë“œ
      2) í…ìŠ¤íŠ¸ ì²­í¬ë¡œ ë¶„í• 
      3) OpenAI ì„ë² ë”© ê³„ì‚°
      4) ES_POLICY_INDEX ì— ì¸ë±ì‹±
    """
    create_policy_index_if_needed()

    splitter = RecursiveCharacterTextSplitter(
        chunk_size=1000,
        chunk_overlap=150,
        separators=["\n\n", "\n", " ", ""],
    )

    from tqdm import tqdm

    for path in pdf_paths:
        print(f"[INFO] indexing policy pdf: {path}")
        reader = PdfReader(path)
        pages = [page.extract_text() or "" for page in reader.pages]

        docs = []
        for i, text in enumerate(pages):
            docs.append(
                {
                    "page_content": text,
                    "metadata": {
                        "source_file": path,
                        "page": i,
                    },
                }
            )

        # 2) ì²­í¬ ë¶„í• 
        texts = [d["page_content"] for d in docs]
        # ê°„ë‹¨í•˜ê²Œ splitterë¥¼ ì§ì ‘ ì ìš©
        chunks = splitter.create_documents(texts)

        pub_date = parse_date_from_filename(path)

        # 3) OpenAI ì„ë² ë”© ê³„ì‚° (ì²­í¬ ë‹¨ìœ„)
        contents = [c.page_content for c in chunks]
        vectors = embedding_model.embed_documents(contents)

        # 4) ES ì¸ë±ì‹±
        for content, vec in tqdm(zip(contents, vectors), total=len(contents)):
            body = {
                "content": content,
                "embedding": vec,
                "policy_name": os.path.basename(path),
                "published_date": pub_date,
                "source_file": path,
            }
            es.index(index=ES_POLICY_INDEX, document=body)

    print("[INFO] policy pdf indexing done.")

index_policy_pdfs(POLICY_PDFS)

# ===== 4. í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ + í‰ê· ê°€ + ìƒí™˜ ê³„ì‚° =====
from typing import List, Dict, Any, Tuple, Optional
from datetime import date, timedelta

ES_REAL_INDEX = os.getenv("ES_REAL_INDEX", "realestate_hybrid")  # ë„¤ ì‹¤ê±°ë˜ ì¸ë±ìŠ¤ ì´ë¦„

def rrf_combine(sparse_hits, dense_hits, k: int = 60, top_k: int = 10):
    """
    Reciprocal Rank Fusion (RRF) ë¡œ sparse/dense ê²°ê³¼ í•©ì¹˜ê¸°
    """
    scores = {}
    for rank, h in enumerate(sparse_hits, start=1):
        _id = h["_id"]
        scores.setdefault(_id, 0.0)
        scores[_id] += 1.0 / (k + rank)

    for rank, h in enumerate(dense_hits, start=1):
        _id = h["_id"]
        scores.setdefault(_id, 0.0)
        scores[_id] += 1.0 / (k + rank)

    id_to_doc = {h["_id"]: h for h in sparse_hits}
    id_to_doc.update({h["_id"]: h for h in dense_hits})

    ranked = sorted(scores.items(), key=lambda x: x[1], reverse=True)[:top_k]
    return [id_to_doc[_id] for _id, _ in ranked]


def hybrid_search_apt(
    query: str = "",
    gu: str = "",
    dong: str = "",
    min_price_krw: int = 0,
    max_price_krw: int = 0,
    area_center: float = 0.0,
    area_tol: float = 3.0,
    min_year_built: int = 0,
    max_year_built: int = 0,
    recent_months: int = 0,
    size: int = 10,
) -> List[Dict[str, Any]]:
    """
    ì‹¤ê±°ë˜ ì¸ë±ìŠ¤(ES_REAL_INDEX)ë¥¼ ëŒ€ìƒìœ¼ë¡œ í•˜ëŠ” í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰.
    - ì›ë˜ëŠ” sparse + dense(RRF)ì¸ë°,
    - dense(dim mismatch ë“±) ì‹¤íŒ¨ ì‹œì—ëŠ” ìë™ìœ¼ë¡œ sparse-only ë¡œ fallback.
    """
    check_es()

    filters = []
    if gu:
        filters.append({"term": {"gu": gu}})
    if dong:
        filters.append({"term": {"dong": dong}})

    if min_price_krw or max_price_krw:
        price_range = {}
        if min_price_krw:
            price_range["gte"] = min_price_krw
        if max_price_krw:
            price_range["lte"] = max_price_krw
        filters.append({"range": {"price_krw": price_range}})

    if area_center:
        filters.append(
            {
                "range": {
                    "area_m2": {
                        "gte": area_center - area_tol,
                        "lte": area_center + area_tol,
                    }
                }
            }
        )

    if min_year_built or max_year_built:
        year_range = {}
        if min_year_built:
            year_range["gte"] = min_year_built
        if max_year_built:
            year_range["lte"] = max_year_built
        filters.append({"range": {"year_built": year_range}})

    if recent_months:
        end = date.today()
        start = end - timedelta(days=30 * recent_months)
        filters.append(
            {
                "range": {
                    "deal_date": {
                        "gte": start.isoformat(),
                        "lte": end.isoformat(),
                    }
                }
            }
        )

# ---------- 1) Dense ê²€ìƒ‰ (ì‹¤íŒ¨ ì‹œ ë¬´ì‹œ) ----------
    dense_hits = []
    query_text = query or f"{gu} {dong}"
    try:
        vec = embed_query(query_text)
        dense_res = es.search(
            index=ES_REAL_INDEX,
            knn={
                "field": "embedding",          # ì¸ë±ìŠ¤ì˜ dense_vector í•„ë“œëª…
                "query_vector": vec,
                "k": size * 2,
                "num_candidates": size * 4,
            },
            _source=True,
        )
        dense_hits = dense_res["hits"]["hits"]
    except Exception as e:
        # ì—¬ê¸°ì„œ ë°©ê¸ˆ ë³¸ dimension mismatch ì—ëŸ¬ë¥¼ ì¡ìŒ
        print("[WARN] Dense ê²€ìƒ‰ ì‹¤íŒ¨, sparse-only ëª¨ë“œë¡œ ë™ì‘í•©ë‹ˆë‹¤:", repr(e))
        dense_hits = []

    # ---------- 2) Sparse ê²€ìƒ‰ ----------
    bool_q = {"must": [], "filter": filters}
    if query:
        bool_q["must"].append(
            {
                "multi_match": {
                    "query": query,
                    "fields": [
                        "apt_name^3",
                        "gu^2",
                        "dong^2",
                        "road_address",
                        "description",
                    ],
                }
            }
        )

    sparse_res = es.search(
        index=ES_REAL_INDEX,
        size=size * 2,
        query={"bool": bool_q},
        _source=True,
    )
    sparse_hits = sparse_res["hits"]["hits"]

     # ---------- 3) RRF ê²°í•© (dense ì—†ìœ¼ë©´ ì‚¬ì‹¤ìƒ sparse ì •ë ¬) ----------
    fused_hits = rrf_combine(sparse_hits, dense_hits, top_k=size)

    rows = []
    for h in fused_hits:
        src = h["_source"]
        rows.append(
            {
                "gu": src.get("gu"),
                "dong": src.get("dong"),
                "apt_name": src.get("apt_name"),
                "deal_date": src.get("deal_date"),
                "area_m2": src.get("area_m2"),
                "year_built": src.get("year_built"),
                "price_krw": src.get("price_krw"),
            }
        )
    return rows


def avg_price_last_3m(gu: str, area_center: float, tol: float = 1.5) -> Tuple[Optional[float], int]:
    """
    ìµœê·¼ 3ê°œì›”ê°„ 'êµ¬ + ë©´ì ëŒ€' í‰ê·  ì‹¤ê±°ë˜ê°€.
    """
    check_es()
    today = date.today()
    start = (today - timedelta(days=90)).isoformat()
    end = today.isoformat()

    body = {
        "size": 0,
        "query": {
            "bool": {
                "must": [
                    {"term": {"gu": gu}},
                    {"range": {"deal_date": {"gte": start, "lte": end}}},
                    {
                        "range": {
                            "area_m2": {
                                "gte": area_center - tol,
                                "lte": area_center + tol,
                            }
                        }
                    },
                ]
            }
        },
        "aggs": {"avg_price": {"avg": {"field": "price_krw"}}},
    }
    res = es.search(index=ES_REAL_INDEX, body=body)
    avg = res["aggregations"]["avg_price"]["value"]
    count = res["hits"]["total"]["value"]
    if avg is None:
        return None, int(count)
    return float(avg), int(count)


def avg_price_last_3m_dong(gu: str, dong: str, area_center: float, tol: float = 1.5) -> Tuple[Optional[float], int]:
    """
    ìµœê·¼ 3ê°œì›”ê°„ 'êµ¬+ë™ + ë©´ì ëŒ€' í‰ê·  ì‹¤ê±°ë˜ê°€.
    """
    check_es()
    today = date.today()
    start = (today - timedelta(days=90)).isoformat()
    end = today.isoformat()

    body = {
        "size": 0,
        "query": {
            "bool": {
                "must": [
                    {"term": {"gu": gu}},
                    {"term": {"dong": dong}},
                    {"range": {"deal_date": {"gte": start, "lte": end}}},
                    {
                        "range": {
                            "area_m2": {
                                "gte": area_center - tol,
                                "lte": area_center + tol,
                            }
                        }
                    },
                ]
            }
        },
        "aggs": {"avg_price": {"avg": {"field": "price_krw"}}},
    }
    res = es.search(index=ES_REAL_INDEX, body=body)
    avg = res["aggregations"]["avg_price"]["value"]
    count = res["hits"]["total"]["value"]
    if avg is None:
        return None, int(count)
    return float(avg), int(count)


def loan_payment(principal: int, annual_rate_pct: float, years: int) -> Dict[str, int]:
    """
    ì›ë¦¬ê¸ˆê· ë“± ìƒí™˜ ê³„ì‚°.
    """
    months = years * 12
    if principal <= 0 or months <= 0:
        return {
            "monthly_payment": 0,
            "months": 0,
            "total_payment": 0,
            "total_interest": 0,
        }

    r = (annual_rate_pct / 100.0) / 12.0
    if r == 0:
        monthly = principal / months
    else:
        monthly = principal * (r * (1 + r) ** months) / ((1 + r) ** months - 1)

    total_payment = monthly * months
    total_interest = total_payment - principal
    return {
        "monthly_payment": int(monthly),
        "months": int(months),
        "total_payment": int(total_payment),
        "total_interest": int(total_interest),
    }

# ===== 5. LangChain Tools ì •ì˜ =====
from langchain.tools import tool
from langchain_community.tools.ddg_search import DuckDuckGoSearchRun

ddg_search = DuckDuckGoSearchRun(region="kr-kr", max_results=5)

# í‰ê· ê°€ ìˆ«ìë¥¼ ì‚¬ëŒì´ ì½ê¸° ì¢‹ì€ í˜•ì‹ìœ¼ë¡œ ë°”ê¿”ì£¼ëŠ” í—¬í¼
def _format_price_krw(amount: float) -> str:
    """ì› ë‹¨ìœ„ ê¸ˆì•¡ì„ '1,654,095,055ì› (ì•½ 16ì–µ 5ì²œë§Œ ì›)' í˜•ì‹ìœ¼ë¡œ ë³€í™˜"""
    amount = int(amount)
    eok = amount // 100_000_000          # ì–µ
    man = (amount % 100_000_000) // 10_000  # ë§Œ
    man_rounded = (man // 1000) * 1000   # 1ì²œë§Œ ë‹¨ìœ„ë¡œ ë°˜ì˜¬ë¦¼

    if eok > 0:
        return f"{amount:,}ì› (ì•½ {eok}ì–µ {man_rounded}ë§Œ ì›)"
    else:
        return f"{amount:,}ì›"

@tool
def search_properties(
    query: str = "",
    gu: str = "",
    dong: str = "",
    max_price_krw: int = 0,
    min_price_krw: int = 0,
    area_center: float = 0.0,
    area_tol: float = 3.0,
    max_age_years: int = 0,
    recent_months: int = 0,
    top_k: int = 10,
) -> str:
    """
    ë¶€ë™ì‚° ë§¤ë¬¼ ê²€ìƒ‰ ë„êµ¬ (ES í•˜ì´ë¸Œë¦¬ë“œ).

    - query: ììœ ë¡œìš´ í…ìŠ¤íŠ¸ ("ë§ˆí¬ 59í˜• ì‹ ì¶• 10ì–µ ì´í•˜" ë“±)
    - gu, dong: ì‹œêµ°êµ¬ / ë™ í•„í„°
    - max_price_krw, min_price_krw: ê°€ê²© ë²”ìœ„ (ì› ë‹¨ìœ„)
    - area_center, area_tol: ì „ìš©ë©´ì  ì¤‘ì‹¬ê°’ & í—ˆìš© ì˜¤ì°¨ (ì˜ˆ: 59ã¡ Â± 3ã¡)
    - max_age_years: 'ìµœê·¼ Në…„ ì´ë‚´ ì‹ ì¶•' ì¡°ê±´ì¼ ë•Œ ì‚¬ìš©
    - recent_months: 'ìµœê·¼ Nê°œì›” ê±°ë˜'ë§Œ ë³´ê³  ì‹¶ì„ ë•Œ
    - top_k: ë°˜í™˜í•  ë§¤ë¬¼ ê°œìˆ˜
    """
    min_year_built = 0
    if max_age_years:
        this_year = date.today().year
        min_year_built = this_year - max_age_years

    rows = hybrid_search_apt(
        query=query,
        gu=gu,
        dong=dong,
        min_price_krw=min_price_krw,
        max_price_krw=max_price_krw,
        area_center=area_center,
        area_tol=area_tol,
        min_year_built=min_year_built,
        size=top_k,
        recent_months=recent_months,
    )

    if not rows:
        return "ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤."

    lines = ["[PROPERTY_SEARCH_RESULT]"]
    for i, r in enumerate(rows, start=1):
        lines.append(
            f"{i}. {r['apt_name']} / {r['gu']} {r['dong']} / "
            f"{r['area_m2']}ã¡ / {r['price_krw']:,}ì› / {r['deal_date']} / "
            f"ì¤€ê³µì—°ë„: {r['year_built']}"
        )
    return "\n".join(lines)


@tool(return_direct=True)
def avg_price_gu(gu: str, area_center: float) -> str:
    """
    êµ¬ + ë©´ì ëŒ€ ê¸°ì¤€ ìµœê·¼ 3ê°œì›” í‰ê·  ë§¤ë§¤ê°€ë¥¼ í•œ ë¬¸ì¥ìœ¼ë¡œ ë°˜í™˜.
    """
    avg, cnt = avg_price_last_3m(gu=gu, area_center=area_center)
    if avg is None or cnt == 0:
        return f"í˜„ì¬ {gu} {area_center:.1f}ã¡ ê·¼ì²˜ì—ëŠ” ìµœê·¼ 3ê°œì›” ê±°ë˜ ë‚´ì—­ì´ ì—†ìŠµë‹ˆë‹¤."

    price_text = _format_price_krw(avg)
    return (
        f"{gu} {area_center:.1f}ã¡ëŒ€ ì•„íŒŒíŠ¸ì˜ ìµœê·¼ 3ê°œì›” í‰ê·  ì‹¤ê±°ë˜ê°€ëŠ” "
        f"{price_text} ê¸°ì¤€ì…ë‹ˆë‹¤. (í‘œë³¸ {cnt}ê±´)"
    )

@tool(return_direct=True)
def avg_price_dong(gu: str, dong: str, area_center: float) -> str:
    """
    êµ¬+ë™ + ë©´ì ëŒ€ ê¸°ì¤€ ìµœê·¼ 3ê°œì›” í‰ê·  ë§¤ë§¤ê°€ë¥¼ í•œ ë¬¸ì¥ìœ¼ë¡œ ë°˜í™˜.
    """
    avg, cnt = avg_price_last_3m_dong(gu=gu, dong=dong, area_center=area_center)
    if avg is None or cnt == 0:
        return f"í˜„ì¬ {gu} {dong} {area_center:.1f}ã¡ ê·¼ì²˜ì—ëŠ” ìµœê·¼ 3ê°œì›” ê±°ë˜ ë‚´ì—­ì´ ì—†ìŠµë‹ˆë‹¤."

    price_text = _format_price_krw(avg)
    return (
        f"{gu} {dong} {area_center:.1f}ã¡ëŒ€ ì•„íŒŒíŠ¸ì˜ ìµœê·¼ 3ê°œì›” í‰ê·  ì‹¤ê±°ë˜ê°€ëŠ” "
        f"{price_text} ê¸°ì¤€ì…ë‹ˆë‹¤. (í‘œë³¸ {cnt}ê±´)"
    )



@tool
def loan_policy_limit(query: str) -> str:
    """
    ì£¼íƒë‹´ë³´ëŒ€ì¶œ í•œë„ë¥¼ ì¶”ì •í•˜ëŠ” ì •ì±… RAG ë„êµ¬ (ì‹¬í”Œ+ìš°ëŒ€ì¡°ê±´ ë°˜ì˜ ë²„ì „).

    query ì•ˆì—ëŠ” ë‹¤ìŒ ì •ë³´ë¥¼ ìì—°ì–´ë¡œ ìµœëŒ€í•œ í¬í•¨í•´ì„œ ë„£ëŠ”ë‹¤.
    - ì£¼íƒê°€ê²©(ì˜ˆ: 16ì–µ, 8ì–µ5ì²œ ë“±)
    - ë³´ìœ  í˜„ê¸ˆ(ìˆë‹¤ë©´)
    - ì§€ì—­(êµ¬ ë‹¨ìœ„) / ê·œì œì§€ì—­ ì—¬ë¶€(íˆ¬ê¸°ê³¼ì—´ì§€êµ¬, ì¡°ì •ëŒ€ìƒì§€ì—­, ë¹„ê·œì œ ë“±)
    - ê°€êµ¬ ìœ í˜•: ë¬´ì£¼íƒ, 1ì£¼íƒ ê°ˆì•„íƒ€ê¸°, ë‹¤ì£¼íƒ, ìƒì• ìµœì´ˆ, ì‹ í˜¼ë¶€ë¶€ ë“±
    - í•œë„ë§Œ ê°„ë‹¨íˆ ì•Œê³  ì‹¶ë‹¤ëŠ” ì˜ë„

    ì˜ˆì‹œ:
    "2025ë…„ ê¸°ì¤€ ì„œìš¸ ë§ˆí¬êµ¬(íˆ¬ê¸°ê³¼ì—´ì§€êµ¬) 16ì–µì§œë¦¬ 84ì œê³± ì•„íŒŒíŠ¸ë¥¼
     ìƒì• ìµœì´ˆë¡œ êµ¬ì…í•˜ë ¤ëŠ” ë¬´ì£¼íƒ ì‹ í˜¼ë¶€ë¶€ì´ê³ , ë³´ìœ  í˜„ê¸ˆì€ 5ì–µì´ë‹¤.
     ì •ì±…ìƒ ë°›ì„ ìˆ˜ ìˆëŠ” ì£¼íƒë‹´ë³´ëŒ€ì¶œ í•œë„ë¥¼ ëŒ€ëµ ì•Œê³  ì‹¶ë‹¤."
    """

    check_es()

    # 1) ì •ì±… PDFì—ì„œ ê´€ë ¨ ë¬¸ë‹¨ ê²€ìƒ‰
    vec = embed_query(query)
    res = es.search(
        index=ES_POLICY_INDEX,
        knn={
            "field": "embedding",
            "query_vector": vec,
            "k": 6,
            "num_candidates": 12,
        },
        _source=True,
    )
    chunks = [h["_source"]["content"] for h in res["hits"]["hits"]]
    if not chunks:
        return "[LOAN_POLICY_LIMIT]\nê´€ë ¨ ì •ì±… ë¬¸ì„œë¥¼ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤."

    context = "\n\n---\n\n".join(chunks)

    # 2) LLMì—ê²Œ ìš”ì•½ ì§€ì‹œ
    prompt = f"""
ë„ˆëŠ” í•œêµ­ ì£¼íƒë‹´ë³´ëŒ€ì¶œ ìƒë‹´ì‚¬ë‹¤.

[ì‚¬ìš©ì ì§ˆë¬¸]
{query}

[ì •ì±… ë¬¸ì„œ ë°œì·Œ]
{context}

ì—­í• :
1) ìœ„ ì •ì±… ë¬¸ì„œì—ì„œ LTV/DTI/DSR ê´€ë ¨ ê·œì •ì„ ì½ê³ ,
   ì•„ë˜ ì¡°ê±´ì— ë”°ë¼ ì ìš©ë  ìˆ˜ ìˆëŠ” LTV ë¹„ìœ¨ì„ "ëŒ€ëµ í•œ ê°’"ìœ¼ë¡œ í•˜ë‚˜ ì •í•´ë¼.
   - query ì•ˆì— 'ì‹ í˜¼ë¶€ë¶€', 'ìƒì• ìµœì´ˆ', 'ë¬´ì£¼íƒ' ë“±ì´ ìˆìœ¼ë©´,
     í•´ë‹¹ ìš°ëŒ€ ê·œì •(ìƒì• ìµœì´ˆ/ì‹ í˜¼ë¶€ë¶€ íŠ¹ë¡€ ë“±)ì„ ìš°ì„  ê³ ë ¤í•œë‹¤.
   - '1ì£¼íƒ', 'ê°ˆì•„íƒ€ê¸°'ê°€ ì–¸ê¸‰ë˜ë©´, ê¸°ì¡´ ì£¼íƒ ë³´ìœ ì— ë”°ë¥¸ ê·œì œ(LTV ì¶•ì†Œ, ì²˜ë¶„ ì¡°ê±´ ë“±)ë¥¼ ê³ ë ¤í•œë‹¤.
   - ë³„ë„ í‘œí˜„ì´ ì—†ìœ¼ë©´ ì¼ë°˜ ë¬´ì£¼íƒ ê°€êµ¬ë¡œ ê°€ì •í•œë‹¤.
2) ì‚¬ìš©ìê°€ ë§í•œ ì£¼íƒê°€ê²©ì„ ê¸°ì¤€ìœ¼ë¡œ ì´ë¡ ìƒ ìµœëŒ€ ëŒ€ì¶œ ê°€ëŠ¥ ê¸ˆì•¡ì„ ê³„ì‚°í•˜ë˜,
   ê³„ì‚° ê³¼ì •ì€ ë„¤ ë¨¸ë¦¿ì†ì—ì„œ í•˜ê³ , ìµœì¢… ê²°ê³¼ë§Œ ë§í•´ë¼.
3) í•œêµ­ ì‹¤ë¬´ ê´€í–‰ìƒ ì¼ë°˜ì ì¸ ìµœëŒ€ í•œë„ë¥¼ 6ì–µì› ìˆ˜ì¤€ìœ¼ë¡œ ë³¸ë‹¤ê³  ê°€ì •í•˜ê³ ,
   ê³„ì‚°ìƒ ê¸ˆì•¡ì´ 6ì–µì›ì„ ì´ˆê³¼í•˜ë©´
   "ê³„ì‚°ìƒì€ Xì–µì´ì§€ë§Œ ì •ì±…ìƒ ì¼ë°˜ í•œë„ëŠ” 6ì–µ ì›ì´ë¼ ì‹¤ì œë¡œëŠ” 6ì–µ ì› ìˆ˜ì¤€"ì´ë¼ê³  ì„¤ëª…í•˜ë¼.
4) DTI/DSRì€ ìˆ«ìë¥¼ ìì„¸íˆ ë§í•  í•„ìš”ëŠ” ì—†ê³ ,
   - ë¬´ì£¼íƒ/ì‹ í˜¼ë¶€ë¶€ì˜ ê²½ìš° "DTI/DSR ë²”ìœ„ ë‚´ì—ì„œ 6ì–µ ì› ìˆ˜ì¤€ì„ ê¸°ëŒ€í•  ìˆ˜ ìˆë‹¤" ì •ë„ë¡œ,
   - 1ì£¼íƒ/ë‹¤ì£¼íƒì˜ ê²½ìš° "DTI/DSR ë° ë³´ìœ  ì£¼íƒìˆ˜ì— ë”°ë¼ ì‹¤ì œ í•œë„ëŠ” ë” ì¤„ì–´ë“¤ ìˆ˜ ìˆë‹¤" ì •ë„ë¡œ
   í•œ ë¬¸ì¥ë§Œ ì–¸ê¸‰í•˜ë¼.

ì¶œë ¥ í˜•ì‹ (ë°˜ë“œì‹œ í•œ ì¤„, ë¬¸ì¥ í•˜ë‚˜ë§Œ):
- ì£¼íƒê°€ê²©, ì ìš© LTV(ëŒ€ëµ ê°’), ëŒ€ëµì ì¸ ìµœëŒ€ ëŒ€ì¶œ ê°€ëŠ¥ ê¸ˆì•¡(ì–µ ë‹¨ìœ„ ë°˜ì˜¬ë¦¼),
  ì‹ í˜¼ë¶€ë¶€/ìƒì• ìµœì´ˆ/1ì£¼íƒ ì—¬ë¶€ì— ë”°ë¥¸ ì½”ë©˜íŠ¸, 6ì–µì› ìƒí•œ ì—¬ë¶€ë¥¼ ëª¨ë‘ í¬í•¨í•´
  ìì—°ìŠ¤ëŸ½ê²Œ í•œ ë¬¸ì¥ìœ¼ë¡œ ì„¤ëª…í•  ê²ƒ.
- ì˜ˆì‹œ:
  "ë¬´ì£¼íƒ ì‹ í˜¼ë¶€ë¶€ê°€ 16ì–µ ì› ì•„íŒŒíŠ¸ë¥¼ êµ¬ì…í•  ê²½ìš° ìƒì• ìµœì´ˆ ìš°ëŒ€ë¥¼ ë°˜ì˜í•´ LTV ì•½ 40%ë¥¼ ì ìš©í•˜ë©´
   ê³„ì‚°ìƒ ìµœëŒ€ ëŒ€ì¶œì€ ì•½ 6ì–µ 4ì²œë§Œ ì›ì´ì§€ë§Œ, ì •ì±…ìƒ ì¼ë°˜ í•œë„ê°€ 6ì–µ ì›ì´ë¼ ì‹¤ì œ ë°›ì„ ìˆ˜ ìˆëŠ” í•œë„ëŠ”
   ì•½ 6ì–µ ì› ìˆ˜ì¤€ì´ë©° DSR ê·œì œì— ë”°ë¼ ë‹¤ì†Œ ì¡°ì •ë  ìˆ˜ ìˆìŠµë‹ˆë‹¤."

ê·¸ ì™¸ ë¶ˆí•„ìš”í•œ ì„¤ëª…ì´ë‚˜ ì—¬ëŸ¬ ë¬¸ì¥ì€ ì“°ì§€ ë§ê³ ,
ìœ„ ì˜ˆì‹œì²˜ëŸ¼ í•œ ì¤„ì§œë¦¬ í•œêµ­ì–´ ë¬¸ì¥ë§Œ ì¶œë ¥í•˜ë¼.
"""

    answer = llm.invoke(prompt)
    return "[LOAN_POLICY_LIMIT]\n" + answer.content



@tool
def loan_simulation(total_price_krw: int, cash_krw: int, annual_rate_pct: float = 3.8, years: int = 30) -> str:
    """
    ë§¤ë§¤ê°€/ìê¸°ìë³¸/ê¸ˆë¦¬/ê¸°ê°„ì„ ì…ë ¥í•˜ë©´ ëŒ€ì¶œ ì›ë¦¬ê¸ˆ ìƒí™˜ ìŠ¤ì¼€ì¤„ ìš”ì•½.
    """
    principal = total_price_krw - cash_krw
    if principal <= 0:
        return (
            "[LOAN_SIMULATION]\n"
            f"ë§¤ë§¤ê°€ {total_price_krw:,}ì›, í˜„ê¸ˆ {cash_krw:,}ì› ê¸°ì¤€ìœ¼ë¡œ ëŒ€ì¶œì´ í•„ìš”í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤."
        )
    res = loan_payment(principal, annual_rate_pct, years)
    return (
        "[LOAN_SIMULATION]\n"
        f"ëŒ€ì¶œ ì›ê¸ˆ: {principal:,}ì›\n"
        f"ì—° ì´ììœ¨: {annual_rate_pct:.2f}% / ê¸°ê°„: {years}ë…„({res['months']}ê°œì›”)\n"
        f"ì›” ìƒí™˜ì•¡: {res['monthly_payment']:,}ì›\n"
        f"ì´ ìƒí™˜ì•¡: {res['total_payment']:,}ì› (ì´ì {res['total_interest']:,}ì›)"
    )


@tool
def policy_news_search(query: str) -> str:
    """
    DuckDuckGo Web Search ê¸°ë°˜ ì •ì±… ë‰´ìŠ¤/ë™í–¥ ê²€ìƒ‰ (ì™¸ë¶€ ë„êµ¬ ìš”ê±´).
    """
    result = ddg_search.run(query + " ì£¼íƒë‹´ë³´ëŒ€ì¶œ ì •ì±… ë³€í™” site:gov.kr OR site:bizinfo.go.kr")
    return f"[POLICY_NEWS]\n{result}"

# ===== 6. Agent êµ¬ì„± =====
from langchain.agents import initialize_agent, AgentType
from langchain.memory import ConversationBufferMemory

def get_llm():
    # í•„ìš”í•˜ë©´ temperature ì¡°ì ˆí•´ì„œ ë²„ì „ ë°”ê¿”ë„ ë¨
    return llm  # ìœ„ì—ì„œ ë§Œë“  ChatOpenAI ì¸ìŠ¤í„´ìŠ¤ ì¬ì‚¬ìš©

tools = [
    search_properties,
    avg_price_gu,
    avg_price_dong,
    loan_policy_limit,
    loan_simulation,
    policy_news_search,
]

memory = ConversationBufferMemory(
    memory_key="chat_history",
    return_messages=True,
)

SYSTEM_PROMPT = """
ë„ˆëŠ” í•œêµ­ ë¶€ë™ì‚° ìƒë‹´ AI ì—ì´ì „íŠ¸ì•¼.

ëŒ€í™” íë¦„ì€ ê¸°ë³¸ì ìœ¼ë¡œ ë‹¤ìŒê³¼ ê°™ì´ ì§„í–‰í•˜ë¼:
1) ì‚¬ìš©ìì˜ ì˜ˆì‚°/ë©´ì /ì§€ì—­ ì¡°ê±´ì„ íŒŒì•…í•œ ë’¤, search_properties ë„êµ¬ë¡œ í›„ë³´ ì•„íŒŒíŠ¸ë¥¼ ì°¾ëŠ”ë‹¤.
2) ê°™ì€ ë©´ì ëŒ€ì˜ ìµœê·¼ 3ê°œì›” í‰ê· ê°€ê²©ì„ avg_price_gu ë˜ëŠ” avg_price_dong ë„êµ¬ë¡œ ì¡°íšŒí•˜ì—¬,
   'í›„ë³´ ë§¤ë¬¼ì´ í‰ê·  ëŒ€ë¹„ ë¹„ì‹¼ì§€/ì‹¼ì§€'ë¥¼ í•¨ê»˜ ì„¤ëª…í•œë‹¤.
3) ì‚¬ìš©ìê°€ ëŒ€ì¶œ/í•œë„ë¥¼ ë¬¼ì–´ë³´ë©´ loan_policy_limit ë„êµ¬ë¥¼ ì‚¬ìš©í•´
   ìµœê·¼ 3ê°œ ì •ì±… PDF (gov_policy_korea ì¸ë±ìŠ¤)ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ëŒ€ëµì ì¸ í•œë„ë¥¼ ì¶”ì •í•œë‹¤.
4) ì´í›„ loan_simulation ë„êµ¬ë¥¼ ì‚¬ìš©í•´ ì›” ìƒí™˜ì•¡/ì´ ìƒí™˜ì•¡ì„ ê³„ì‚°í•œë‹¤.
5) ì •ì±… ë¦¬ìŠ¤í¬ë‚˜ í–¥í›„ ë³€í™” ê°€ëŠ¥ì„±ì„ ì„¤ëª…í•  ë•Œë§Œ policy_news_search ë„êµ¬ë¥¼ ì‚¬ìš©í•´
   ìµœì‹  ì •ì±…/ë‰´ìŠ¤ ë™í–¥ì„ ë§ë¶™ì—¬ë¼.
6) ì—¬ëŸ¬ í„´ì— ê±¸ì³ ì‚¬ìš©ìì˜ ì¡°ê±´(ì—°ì†Œë“, ë¬´ì£¼íƒ ì—¬ë¶€, í¬ë§ ì§€ì—­, ì˜ˆì‚°)ì„ ê¸°ì–µí•˜ê³  í™œìš©í•˜ë¼.

ì¶”ê°€ ê·œì¹™:
- ë„êµ¬(íŠ¹íˆ [AVG_PRICE_GU], [AVG_PRICE_DONG], [LOAN_POLICY_LIMIT])ì—ì„œ ì œê³µí•œ ìˆ«ì ê°’(ê°€ê²©, ì›” ìƒí™˜ì•¡ ë“±)ì€
  ê·¸ëŒ€ë¡œ ì‹ ë¢°í•´ì•¼ í•œë‹¤. Final Answerì—ì„œ ì´ ìˆ«ìë¥¼ ë‹¤ì‹œ ê³„ì‚°í•˜ê±°ë‚˜ ìë¦¿ìˆ˜ë¥¼ ë°”ê¾¸ì§€ ë§ ê²ƒ.
- 'ìµœê·¼ 3ê°œì›” í‰ê·  ì‹¤ê±°ë˜ê°€: 1,654,095,055ì›'ì²˜ëŸ¼ ë‚˜ì˜¤ë©´,
  ë‹µë³€ì—ì„œëŠ” 'ìµœê·¼ 3ê°œì›” í‰ê·  ê±°ë˜ê°€ëŠ” 1,654,095,055ì›(ì•½ 16ì–µ 5ì²œë§Œ ì›)ì…ë‹ˆë‹¤.'ì²˜ëŸ¼
  **ë„êµ¬ê°€ ì¤€ ìˆ«ìë¥¼ ê·¸ëŒ€ë¡œ ì“°ê³ , í•„ìš”í•˜ë©´ ì˜†ì— ì–µ ë‹¨ìœ„ ì„¤ëª…ë§Œ ë§ë¶™ì—¬ë¼.**
- 1,654,095,055ì› ê°™ì€ ê°’ì„ 1ì–µëŒ€ë¡œ ì˜ëª» ì¤„ì—¬ ì“°ì§€ ë§ê³ ,
  ìµœì†Œí•œ ì•ì˜ ë‘ ìë¦¬(16ì–µ) ìˆ˜ì¤€ì€ ì •í™•íˆ ìœ ì§€í•´ì•¼ í•œë‹¤
"""

agent_llm = get_llm()

agent = initialize_agent(
    tools=tools,
    llm=agent_llm,
    agent=AgentType.STRUCTURED_CHAT_ZERO_SHOT_REACT_DESCRIPTION,  # âœ… ì—¬ê¸° ë³€ê²½
    memory=memory,
    verbose=False,
    agent_kwargs={"system_message": SYSTEM_PROMPT},
)

def chat_realestate_agent(user_input: str) -> str:
    return agent.run(user_input)

chat_realestate_agent("ë§ˆí¬êµ¬ 59ã¡, ì˜ˆì‚° 10ì–µ ì •ë„ë¡œ ì§‘ ì¶”ì²œí•´ì¤˜.")

resp1 = chat_realestate_agent("ë§ˆí¬êµ¬ 59ì œê³±, ì˜ˆì‚° 10ì–µ ì •ë„ë¡œ ì§‘ ì¶”ì²œí•´ì¤˜.")
resp2 = chat_realestate_agent("ê·¸ëŸ¼ ë§ˆí¬êµ¬ 84ì œê³±ì€ ìµœê·¼ 3ê°œì›” í‰ê·  ê±°ë˜ê°€ ì–¼ë§ˆì•¼?")
print(resp1)
print("------")
print(resp2)

resp3 = chat_realestate_agent(
    "ë°©ê¸ˆ ë§í•œ ë§ˆí¬êµ¬ 84ì œê³± ì•„íŒŒíŠ¸ í‰ê·  ë§¤ë§¤ê°€ë¥¼ 16ì–µ 5ì²œë§Œ ì› ì •ë„ë¼ê³  ê°€ì •í•˜ë©´, "
    "ë‚˜ëŠ” ë¬´ì£¼íƒ ì‹ í˜¼ë¶€ë¶€ê³  ë³´ìœ  í˜„ê¸ˆì€ 5ì–µ ì›ì´ì•¼. "
    "í˜„ì¬ ì£¼íƒë‹´ë³´ëŒ€ì¶œ ì •ì±… ê¸°ì¤€ìœ¼ë¡œ ë°›ì„ ìˆ˜ ìˆëŠ” ëŒ€ì¶œ í•œë„ê°€ "
    "LTV ê¸°ì¤€ìœ¼ë¡œ ì–´ëŠ ì •ë„ì¸ì§€ í•œ ì¤„ë¡œë§Œ ì„¤ëª…í•´ì¤˜."
)
print(resp3)

resp4 = chat_realestate_agent(
    "ì•„ê¹Œ ì •ì±… ê¸°ì¤€ìœ¼ë¡œ ìµœëŒ€ ëŒ€ì¶œ ê°€ëŠ¥ ê¸ˆì•¡ì´ ì•½ 6ì–µ ì› ì •ë„ë¼ê³  í–ˆì–ì•„. "
    "ê·¸ì¤‘ 4ì–µ ì›ì„ ì—° 3.8% ê¸ˆë¦¬, 30ë…„ ì›ë¦¬ê¸ˆê· ë“± ìƒí™˜ìœ¼ë¡œ ëŒ€ì¶œë°›ëŠ”ë‹¤ê³  í•˜ë©´ "
    "ì›” ìƒí™˜ì•¡ê³¼ ì´ ìƒí™˜ì•¡, ì´ ì´ì ë¶€ë‹´ì„ ê³„ì‚°í•´ì„œ ì•Œë ¤ì¤˜."
)
print(resp4)

